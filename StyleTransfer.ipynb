{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "StyleTransfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOA8ztpuY6NOf0w1r5A2BUV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nawta/Style-Transfer/blob/main/StyleTransfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhRTtZHx_KUM"
      },
      "source": [
        "モジュールのインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X84HH1pDAfoz"
      },
      "source": [
        "import os\n",
        "#from urllib.request import urlretrieve\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications import vgg19\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-43W5-uDx-J"
      },
      "source": [
        "#ドライブに保存したりファイルを取ってくるのに使う。Colaboratoryの環境下のcontent/drive/My driveにドライブのファイル類がマウントされる。\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrHBMK3KBHCg"
      },
      "source": [
        "class TransferDefinition():\n",
        "\n",
        "    def __init__(self, content_image_path, style_image_path, img_nrows=400):\n",
        "        self.width, self.height = load_img(content_image_path).size\n",
        "        self.img_nrows = img_nrows\n",
        "        self.img_ncols = int(self.width * self.img_nrows / self.height)\n",
        "\n",
        "    def preprocess_image(self, image_path):\n",
        "        img = load_img(image_path, target_size=(self.img_nrows, self.img_ncols))\n",
        "        img = img_to_array(img)\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        img = vgg19.preprocess_input(img)\n",
        "        return img\n",
        "\n",
        "    def deprocess_image(self, x):\n",
        "        img = x.copy()\n",
        "        img = img.reshape(self.img_nrows, self.img_ncols, 3)\n",
        "        # Remove zero-center by mean pixel\n",
        "        img[:, :, 0] += 103.939\n",
        "        img[:, :, 1] += 116.779\n",
        "        img[:, :, 2] += 123.68\n",
        "        # \"BGR\"->\"RGB\"\n",
        "        img = img[:, :, ::-1]\n",
        "        img = np.clip(img, 0, 255).astype(\"uint8\")\n",
        "        return img\n",
        "\n",
        "\n",
        "def gram_matrix(x):\n",
        "    assert K.ndim(x) == 3\n",
        "    features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
        "    gram = K.dot(features, K.transpose(features))\n",
        "    return gram\n",
        "\n",
        "\n",
        "def content_loss(content, combination):\n",
        "    return K.sum(K.square(combination - content))\n",
        "\n",
        "\n",
        "def style_loss(tdef, style, combination):\n",
        "    assert K.ndim(style) == 3\n",
        "    assert K.ndim(combination) == 3\n",
        "    S = gram_matrix(style)\n",
        "    C = gram_matrix(combination)\n",
        "    channels = 3\n",
        "    size = tdef.img_nrows * tdef.img_ncols\n",
        "    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))\n",
        "\n",
        "\n",
        "def total_variation_loss(tdef, x):\n",
        "    assert K.ndim(x) == 4\n",
        "    a = K.square(x[:, :tdef.img_nrows - 1, :tdef.img_ncols - 1, :] - x[:, 1:, :tdef.img_ncols - 1, :])  # noqa\n",
        "    b = K.square(x[:, :tdef.img_nrows - 1, :tdef.img_ncols - 1, :] - x[:, :tdef.img_nrows - 1, 1:, :])  # noqa\n",
        "    return K.sum(K.pow(a + b, 1.25))\n",
        "\n",
        "\n",
        "def main(content_image_path, style_image_path, iter_count=10,\n",
        "         content_weight=1.0, style_weight=0.1, total_variation_weight=0.001,\n",
        "         learning_rate=0.001):\n",
        "    tdef = TransferDefinition(content_image_path, style_image_path)\n",
        "\n",
        "    # inputs\n",
        "    content_image = K.variable(tdef.preprocess_image(content_image_path))\n",
        "    style_image = K.variable(tdef.preprocess_image(style_image_path))\n",
        "    # generated image\n",
        "    combination_image = K.placeholder((1, tdef.img_nrows, tdef.img_ncols, 3))\n",
        "    input_tensor = K.concatenate([content_image,\n",
        "                                  style_image,\n",
        "                                  combination_image], axis=0)\n",
        "\n",
        "    # load pre-trained model\n",
        "    model = vgg19.VGG19(input_tensor=input_tensor,\n",
        "                        weights=\"imagenet\", include_top=False)\n",
        "    outputs_dict = dict([(layer.name, layer.output)\n",
        "                        for layer in model.layers])\n",
        "\n",
        "    # define loss\n",
        "    loss = K.variable(0.)\n",
        "    feature_map = outputs_dict[\"block5_conv2\"]\n",
        "    feature_of_content = feature_map[0, :, :, :]\n",
        "    feature_of_combination = feature_map[2, :, :, :]\n",
        "\n",
        "    loss = loss + content_weight * content_loss(\n",
        "                                    feature_of_content,\n",
        "                                    feature_of_combination)\n",
        "\n",
        "    feature_layers = [\"block1_conv1\", \"block2_conv1\",\n",
        "                      \"block3_conv1\", \"block4_conv1\",\n",
        "                      \"block5_conv1\"]\n",
        "\n",
        "    for layer_name in feature_layers:\n",
        "        feature_map = outputs_dict[layer_name]\n",
        "        feature_of_style = feature_map[1, :, :, :]\n",
        "        feature_of_combination = feature_map[2, :, :, :]\n",
        "        sl = style_loss(tdef, feature_of_style, feature_of_combination)\n",
        "        loss += (style_weight / len(feature_layers)) * sl\n",
        "\n",
        "    loss += total_variation_weight * total_variation_loss(tdef, combination_image)  # noqa\n",
        "    grads = K.gradients(loss, combination_image)[0]\n",
        "    style_transfer = K.function([combination_image], [loss, grads])\n",
        "\n",
        "    image = tdef.preprocess_image(content_image_path)\n",
        "    for i in range(iter_count):\n",
        "        print(\"Start of iteration {}\".format(i + 1))\n",
        "        loss_value, grad_values = style_transfer([image])\n",
        "        image -= grad_values * learning_rate\n",
        "\n",
        "    fig = plt.figure(figsize=(10, 5))\n",
        "    for kind in [\"original\", \"style\", \"styled\"]:\n",
        "        if kind == \"original\":\n",
        "            img = load_img(content_image_path,\n",
        "                           target_size=(tdef.img_nrows, tdef.img_ncols))\n",
        "            ax = plt.subplot(1, 3, 1)\n",
        "        elif kind == \"style\":\n",
        "            img = load_img(style_image_path,\n",
        "                           target_size=(tdef.img_nrows, tdef.img_ncols))\n",
        "            ax = plt.subplot(1, 3, 2)\n",
        "        elif kind == \"styled\":\n",
        "            img = tdef.deprocess_image(image)\n",
        "            ax = plt.subplot(1, 3, 3)\n",
        "        ax.set_title(kind)\n",
        "        ax.imshow(img)\n",
        "        ax.axis(\"off\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    dir_name, file_name = os.path.split(content_image_path)\n",
        "    file_root, ext = os.path.splitext(file_name)\n",
        "    plt.savefig(os.path.join(dir_name, file_root + \"_styled.png\"))\n",
        "    plt.show()\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7PjsP8H-7Qf",
        "outputId": "4e5d6955-b880-49c1-96b1-03b1530acb18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 787
        }
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    drive_root_dir=\"/content/drive/My Drive\"\n",
        "    image_url = \"http://farm2.static.flickr.com/1200/525304657_c59f741aac.jpg\"\n",
        "    content_path = os.path.join(drive_root_dir + \"/GoogleColaboratory/Style-Transfer\", \"data/content.jpg\")\n",
        "    urlretrieve(image_url, content_path)\n",
        "\n",
        "    image_url = \"https://upload.wikimedia.org/wikipedia/commons/e/ed/Cats_forming_the_caracters_for_catfish.jpg\"  # noqa\n",
        "    style_path = os.path.join(drive_root_dir + \"/GoogleColaboratory/Style-Transfer\", \"data/style.jpg\")\n",
        "    urlretrieve(image_url, style_path)\n",
        "\n",
        "    main(content_path, style_path)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-0dd5540da235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0murlretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-ec57d942d4d0>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(content_image_path, style_image_path, iter_count, content_weight, style_weight, total_variation_weight, learning_rate)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtotal_variation_weight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal_variation_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombination_image\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcombination_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mstyle_transfer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcombination_image\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(loss, variables)\u001b[0m\n\u001b[1;32m   3967\u001b[0m   \"\"\"\n\u001b[1;32m   3968\u001b[0m   return gradients_module.gradients(\n\u001b[0;32m-> 3969\u001b[0;31m       loss, variables, colocate_gradients_with_ops=True)\n\u001b[0m\u001b[1;32m   3970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_impl.py\u001b[0m in \u001b[0;36mgradients\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_ys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_gradients_with_ops\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mgate_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maggregation_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         unconnected_gradients)\n\u001b[0m\u001b[1;32m    173\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gradients_util.py\u001b[0m in \u001b[0;36m_GradientsHelper\u001b[0;34m(ys, xs, grad_ys, name, colocate_gradients_with_ops, gate_gradients, aggregation_method, stop_gradients, unconnected_gradients, src_graph)\u001b[0m\n\u001b[1;32m    489\u001b[0m   \u001b[0;34m\"\"\"Implementation of gradients().\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m     raise RuntimeError(\"tf.gradients is not supported when eager execution \"\n\u001b[0m\u001b[1;32m    492\u001b[0m                        \"is enabled. Use tf.GradientTape instead.\")\n\u001b[1;32m    493\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0msrc_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead."
          ]
        }
      ]
    }
  ]
}